A First Look at Starlink Performance Fran√ßois Michel‚àó UCLouvain francois.michel@uclouvain.be Martino Trevisan University of Trieste martino.trevisan@dia.units.it Danilo Giordano Politecnico di Torino danilo.giordano@polito.it Olivier Bonaventure UCLouvain olivier.bonaventure@uclouvain.be

With new Low Earth Orbit satellite constellations such as Starlink, satellite-based Internet access is becoming an alternative to traditional fixed and wireless technologies with comparable throughputs and latencies. In this paper, we investigate the user-perceived performance of Starlink. Our measurements show that latency remains low and does not vary significantly under idle or lightly loaded links. Compared to another commercial Internet access using a geostationary satellite, Starlink achieves higher TCP throughput and provides faster web browsing. To avoid interference from performance enhancing proxies commonly used in satellite networks, we also use QUIC to assess performance under load and packet loss.

under load for both upload and download. CCS CONCEPTS ‚Ä¢ Networks ‚ÜíNetwork measurement; Wireless access networks. KEYWORDS Starlink, Satellite Communications, Low Earth Orbit, Network Performance, Measurements ACM Reference Format: Fran√ßois Michel, Martino Trevisan, Danilo Giordano, and Olivier Bonaventure. 2022. A First Look at Starlink Performance. In Proceedings of the 22nd ACM Internet Measurement Conference (IMC ‚Äô22), October 25‚Äì27, 2022, Nice, France. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/3517745. 3561416 1

lated Starlink connection, and compare it with other connection technologies (included 3G, 4G, and classical geostationary SatCom with data from ), we have created a data-driven model for the ERRANT network emulator tool  and make it available at https://github.com/SmartData-Polito/errant. 2 TESTBED AND MEASUREMENTS For our experimental campaign, we use three off-the-shelf PCs equipped with 8 cores and 16 GB of memory running Ubuntu 20.04 and Linux kernel version 5.0.4. The two first PCs are located in the UCLouvain campus in Louvain-la-Neuve, Belgium. The first PC (PC-Starlink) is connected to the Internet via Starlink with a regular subscription. The second PC (PC-Wired) is connected to the UCLouvain campus network via a 1 Gbit/s Ethernet adapter. The third PC (PC-SatCom) is connected to the Internet via a traditional SatCom equipment for which we have purchased a regular plan offering up to 100 Mbit/s in downlink and 10 Mbit/s in uplink. The SatCom operator is a reseller and relies on a major European provider that uses geostationary satellites to provide Internet access. Our user equipment consists of a dish antenna and a modem that connects the PC to the network. For each setup, the TCP receive window is the kernel default, i.e. 131072 bytes by default with a maximum of 6291456 bytes through automatic buffer tuning. The congestion control is Cubic. We use the three PCs to run the

Table 1. QUIC measurements. Some of the performance metrics of this article are gathered using the QUIC protocol . We assess the network performance with two kinds of transfers: (i) bulk HTTP/3 (H3)  100MB transfers and (ii) light QUIC transfers with regularly sent messages, similar to a real-time video traffic. The latter sends 25 variable length messages per second during 2 minutes. Each message has a size in the 5-25kB range. The average bitrate of this transfer is 3 Mbit/s, far below both downlink and uplink capacities announced by Starlink. The QUIC client runs on PCStarlink while the server is located in the UCLouvain university

the client (download) and the other half are from the client to the server (upload). Using QUIC instead of TCP ensures that we measure the end-to-end latency as it forbids the use of middleboxes and proxies interfering with the traffic at the transport layer as it can be done for TCP with PEPs. The way QUIC identifies and retransmits packets also allows us to exactly point every lost packet and disambiguating original packets from retransmissions. The QUIC H3 server is able to provide more than 400Mbps of QUIC traffic to other endpoints connected to wired networks outside our campus. The

from commit ba87786. Its initial max_data and max_stream_data transport parameters are set to 10MB and the receive window varies through automatic buffer tuning. The congestion control used is Cubic. Latency. We measure the latency of Starlink by probing a set of 11 anchors using ping. Our set of anchors includes 7 servers used inside the RIPE Atlas project . The servers are located in Europe (Amsterdam √ó2, Nuremberg √ó2), North America (New

data from December 20 to April 7 2022. We compare the browsing experience offered by Starlink with the SatCom link by running the

3

the measured latency and then focus on packet loss and throughput, comparing StarLink with traditional SatCom. Finally, we discuss 131 A First Look at Starlink Performance IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France BE-1 BE-2 BE-3 BE-4 DE-1 DE-2 NL-1 NL-2 SG US 101 102 103 RTT 28.4 28.9 24.7 24.7 20.6 20.2 23.5 23.0 237 161 Min RTT Figure 1: Distribution of the RTT to the anchors. The top ùë• axis reports the distribution minimum. Notice the logarithmic ùë¶axis. 2021/12/15 2022/01/01 2022/01/15 2022/02/01 2022/02/15 2022/03/01 2022/03/15 2022/04/01 2022/04/15 2022/05/01 2022/05/15 0 10 20 30 40 50 60 70 80 RTT 25th perc. Median 75th perc. Minimum Figure 2: RTT towards the European anchors. QoE-related metrics for web browsing and the presence of middleboxes. 3.1 Latency We begin our analysis by looking at the RTT. We first measure the latency without load on the link, which is the best latency Starlink subscribers could achieve. We then perform QUIC downloads and uploads, thus generating bandwidth pressure and study how the RTT evolves under load. Latency during inactivity: Figure 1 shows the distribution of the measured latencies towards our set of anchors. The ùë¶-axis (in logarithmic scale) represents the distribution of RTT measured by ping in the form of a boxplot: boxes range from the 25ùë°‚Ñéto the 75ùë°‚Ñépercentile, while whiskers range from the 5ùë°‚Ñéto the 95ùë°‚Ñé. The black central stroke represents the median, while on the upper ùë• axis we indicate the absolute minimum of the distribution. The 4 left-most boxes are the four local anchors. In the median case, the RTT is in ms and exceeds 70ms in less than 5% of cases. The minimum observed RTT for these anchors is ms. Similar considerations apply to the two Dutch anchors. The lowest RTT we observe is for the two German probes, which PC-Starlink reaches in only 42ms in median. The lowest RTT we observe is 20.5ms, confirming Starlink‚Äôs 20ms latency promise. We observe that these values allow high QoE for voice calls  and are compatible with latency-sensitive services such as cloud gaming. Indeed, GeForce Now, one of the leading platforms, mandates a latency below 80ms . To reach the most distant anchor points in the U.S. (San Francisco) and Asia (Singapore), the RTT is necessarily much higher, but not more than the distance between the endpoints 0.05 0.15 0.25 H3 RTT (s) 0.0 0.2 0.4 0.6 0.8 1.0 CDF Download Upload (a) H3 bulk traffic. 0.05 0.15 0.25 Messages RTT (s) 0.0 0.2 0.4 0.6 0.8 1.0 CDF Download Upload (b) Messages traffic. Figure 3: Measured per-packet RTT distribution. would suggest. San Francisco and Singapore are reached in a median of 184 and 270ms respectively. Using traceroute, we verified the path taken by packets towards San Francisco and Singapour and the exit nodes from the Starlink network were the same as for the European anchors (i.e. one exit in the Netherlands and the other in Germany). This suggests that inter-satellite links (ISL) are not currently enabled, although ISL-capable satellites have been launched  and ISL activation is planned by the end of 2022 . To investigate how latency evolves over time, we depict in Figure 2 various percentiles and the minimum values, focusing on European anchors. The ùë•-axis spans the five months of measurements, and we compute our statistics using 6-hours bins. The picture is fairly flat, indicating stable performance and no particular changes in Starlink infrastructure over this period. The RTT to the European anchors remains constant around 50 ms in median and ranges from 40 ms (25ùë°‚Ñépercentile) to 60ms (75ùë°‚Ñé). The minimum measured latency is on the order of 20 ms. Interestingly, we observe that the distribution takes on slightly smaller values of a few milliseconds from February 11 onwards - see the small step in the middle of the figure. We suspect that this improvement is related to new satellites joining the constellation in early 2022, although we have no direct evidence . Moreover, we observe an increase in RTT during the last week of April and the first week of May. Since, at that time,

period Starlink was more loaded or going through reorganization, but we cannot confirm this. Finally, we observe that distribution of RTT is rather flat over the hours of the day. The median RTT is around 50 ms and a Mood‚Äôs test suggests the samples are drawn from distributions with the same median. Similar considerations hold for throughput measurements as well, and this can hint low utilization of the infrastructure as most operator links are impacted by diurnal patterns. Latency under load: We now study the latency evolution under link pressure. We perform HTTP/3 downloads and uploads towards our server and study the evolution of the RTT during the file transfer. Figure 3 shows the distribution of the RTT for every

session with packets captures on the server as they were too few RTTs samples coming from the client capture for download transfers. Each curve contains more than 2 millions RTT samples. We note a median, 95ùë°‚Ñéand 99ùë°‚Ñépercentiles RTT of 95 (resp. 104), 175 (resp 237) and 210 (resp 310) ms for downloads (resp. uploads). We 132 IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France Michel et al. Table 2: QUIC packet loss ratios H3 ‚Üì H3 ‚Üë Messages ‚Üì Messages ‚Üë 1.56% 1.96% 0.40% 0.45% can see that the RTT increases more for uploads than download. This difference may be explained by the larger available bandwidth for downloads allowing emptying the router queues faster than for uploads, having thus a smaller impact on queuing delay for equally-sized queues. We finally study the RTT evolution with the QUIC messages transfer. Compared to the H3 traffic, the RTT stays mostly under 100ms, similarly to the values we obtain for ping European anchors. The downloads (resp. uploads) have 50 (resp. 66) ms median RTT, 71 (resp 87) ms 95ùë°‚Ñépercentile and 87 (resp. 143) ms 99ùë°‚Ñépercentile RTT. The larger RTT for uploads relates to quiche not implementing packet pacing. The largest messages (25 kB) are thus stacked in the network‚Äôs buffers making the RTT increase lightly. Take Away: The minimum latency of Starlink is in the order of 20 ms for close destinations, as publicly advertised. Under traffic load, it may increase to a few hundreds of milliseconds. 3.2 Characterizing packet losses Packet losses can be caused by congestion or imperfections on the medium. For download, we determine losses by looking at QUIC received packet numbers on the client. As in QUIC retransmitted data have different packet numbers from the original data and as quiche does not introduce packet number gaps, every missing packet number means the packet has been lost. For uploads, we determine the received packets by looking at the ACK frames returned by the server. Packet losses during HTTP/3 transfers: We first study the packet losses encountered during HTTP/3 bulk transfers. In this case, losses can be due to both congestion and medium imperfections. The first two columns of Table 2 show the packet losses recorded during the H3 transfers. We can see that uploads suffered from more loss events than downloads. Nearly 2% of the packets were lost during uploads while a bit more than 1.5% were lost during downloads. Figure 4a shows the measured distribution of the loss bursts lengths during H3 transfers. The loss burst length is the number of consecutively lost packets for each loss event. As we can see, the majority of loss events during uploads concerned only one packet at a time, while more than 75% of loss events during downloads concerned several consecutive packets. We also look at the duration of a loss event. Indeed, some wireless technologies such as 802.11 implement retransmission mechanisms that may delay the arrival of subsequent packets, resulting in small silent periods during the transfer . As packets are captured on the client, we can compute the duration of loss events during downloads. We identified 244 008 loss events. The median loss event duration is 49 microseconds. The 75ùë°‚Ñéand 90ùë°‚Ñépercentiles are respectively 58 and 113 microseconds. The 95ùë°‚Ñéand 99ùë°‚Ñépercentiles are 1.5 and 7.5 milliseconds. We also identified a small number of longer loss periods lasting more than 1 second identifying a possible loss of connectivity. 1 3 5 7 9 11 13 15 loss burst length 0.00 0.25 0.50 0.75 1.00 CDF Download Upload (a) H3 transfers 1 3 5 7 9 111315171921 loss burst length 0.00 0.25 0.50 0.75 1.00 CDF Download Upload (b) Messaging transfers Figure 4: Measured loss bursts distribution. Note that Table 2 shows that packet losses are far less common for messages transfers. Thus, loss burst greater frequency is only apparent. Packet losses during low bitrate transfers: We now focus on the low bitrate messaging use-case. The two last columns of Table 2 show the packet loss ratios measured during those transfers.

slightly smaller for downloads than for uploads. The loss ratio is also significantly lower compared to H3. Given the low bitrate of the messaging use-case and the overall low RTT previously measured, we can expect that fewer packet losses were caused by congestion here. Note however that from the transport viewpoint, there is no known way to distinguish between congestion and medium-induced losses. This is why loss-based congestion control algorithms such as Cubic  interpret every loss event as a congestion signal. Figure 4b shows the loss bursts lengths distribution for the mesin general longer when occurring. We conjecture that most of the

gestion: they are more frequent and only concern a few packets, while the loss events encountered during the messages transfers may be related to the medium, sometimes being even comparable to small network outages with some loss bursts of more than 100 packets (also present for H3 transfers). Concerning the loss events duration, most events for message transfers were shorter than 1ms. However, we noted 95ùë°‚Ñéand 99ùë°‚Ñépercentiles of 104 and 127 ms which are larger than the percentiles for H3 downloads (note that the loss events for message transfers are a lot more rare than H3 loss events and that H3 transfers probably mostly encounter congestioninduced losses). Similarly to H3, we also detected small network outages with loss events lasting more than 1 second. Finally, we checked that those losses were neither caused by our network nor our server by running downloads for both H3 and messages transfers from a machine in Amsterdam (i.e., close to an exit point of the Starlink network) towards our H3 server. For H3 (resp. messages) downloads, over more than 5.8 M (resp. 2.8 M) packets sent by our QUIC server, only 10 (resp. 8) were lost, making loss events nearly absent outside Starlink. Take Away: The loss events occurring when the link is loaded are more frequent and only affect a few consecutive packets. Without link pressure, the loss events are more rare, concern overall more consecutive packets and last longer. 133 A First Look at Starlink Performance IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France 0 100 200 300 400 Download 0.0 0.2 0.4 0.6 0.8 1.0 CDF (a) Download Throughput. 0 10 20 30 40 50 Upload Starlink Ookla Starlink H3 SatCom Ookla (b) Upload Throughput. Figure 5: Measured throughput distribution. 3.3 Throughput

Ookla Speedtest on Starlink, H3 bulk download on Starlink and Ookla Speedtest on the regular SatCom access. We first discuss the

link‚Äôs download throughput ranges between 100 and 250 Mbit/s. The median value is 178 Mbit/s, while the maximum is 386 Mbit/s. This maximum is surprisingly high given the company‚Äôs public statements, i.e., download speeds between 100 Mbit/s and 200 Mbit/s. We note that they enable the use of bandwidth-intensive services, such as High-Definition video streaming. Netflix‚Äôs 4K videos require a download bandwidth of 15 Mbit/s , while Disney+ recommends 25 Mbit/s . The upload throughput, in Figure 5b, is significantly lower, reaching a median of 17 Mbit/s. Fewer than 5% of the cases exceed 30 Mbit/s and the highest observed rate is 64 Mbit/s. For both metrics, we cannot find a seasonality in the measurements. Looking at the different hours of the day, the median throughput varies by less than ¬±10% with no apparent day-night cycle. Furthermore, we have not observed any increasing or decreasing trend in the measureassume approximately the same average values and variability. Comparing with traditional SatCom, we find that Starlink provides higher throughput in both scenarios. Considering download, with a median value of 178 Mbit/s, Starlink is more than twice as fast as SatCom (82 Mbit/s). The situation is similar for upload: the traditional SatCom connection inherently offers lower upload throughput (4.5 Mbit/s in median), as it is limited to a bitrate of 10 Mbit/s. We can briefly compare these values with mobile networks lookmostly between 100 and 150 Mbit/s which is in line with what is

the Ookla TCP speedtests and lower than what our QUIC server can deliver to other wired endpoints. We also excluded the possibility of an incorrect receive window tuning of quiche by running

to the fact that regular speedtests use at least four concurrent TCP connections while the QUIC download uses one single connection, reacting more strongly to losses . It is also possible that Ookla speedtests are prioritized by the operator, similarly to what happens for conventional operators. The measured upload throughput is similar for the two sessions and is in-line with the Ookla

Take Away: In download and upload, Starlink outperforms traditional SatCom.The measured throughput with QUIC is lower compared to TCP speed tests for downloads but similar and more stable than TCP speed tests for uploads. 3.4 Browsing Performance We now quantify the Starlink performance for Web browsing. We compare the user experience of Starlink users against other access technologies. We resort to the onLoad and Speed Index metrics that have been shown to correlate with it . We continuously visit a set of 120 popular websites in our country, using PC-Starlink, PC-SatCom and PC-Wired. In Figure 6, we show the ECDF of QoE-related metrics. Starting from onLoad (Figure 6a), we find that it generally ranges from a few to 15-20 seconds, depending on the website and conditions. Starlink (solid red line), overall, provides a median onLoad of 2.12s and an

with SatCom equipment (blue dashed line) show that onLoad is 1While not present on the graph, all packet captures for the first session will be provided in the artifacts of the article. 134 IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France Michel et al. substantially larger, 10.91s on median. The distribution ranges from 8.36s (25ùë°‚Ñépercentile) to 13.59s (75ùë°‚Ñépercentile). It is likely that this performance is due to the high latency of the SatCom connections, which affects the operation of TCP and HTTP. Note that rendering a web page requires opening multiple connections to different servers

in 15 connections on average. On SatCom, opening a connection (including the TLS handshake) takes an average of 2 030ms, while Starlink requires only 167ms. Finally, the green dashed line reports the baseline performance of a well-functioning wired network. The median onLoad is 1.24s, still considerably lower than the other two

we mention that Rajiullah et al.  use a large testbed of mobile nodes to visit a number of popular websites. They measure onLoad time on the order of 2 ‚àí5s, thus moderately higher than what we measure on Starlink. Similar considerations apply to the SpeedIndex (Figure 6b). Starlink shows a median performance of 1.82s, outperforming SatCom with a 8.19s median SpeedIndex. Starlink performance is closer to the Wired setup, with median of 1.0s. Take Away: For Web browsing, Starlink outperforms SatCom and has close performance to regular wired access. Looking at QoE-related metrics, Starlink is 75 ‚àí80% faster than traditional SatCom. 3.5 Middleboxes and traffic discrimination SatCom solutions often deploy PEPs to alleviate the problems due to the high link latency. Some operators also apply Traffic Discrimination (TD) to control the bandwidth used by applications on their network. In this section, we analyze the presence of middleboxes and TD on the Starlink network. PEPs and middleboxes: We first use traceroute and Tracebox  to detect PEPs and middleboxes. Traceroute shows us the presence of two levels of NAT at the two first nodes: the Starlink access point (192.168.1.1) and a carrier-grade NAT node (100.64.0.1) at the exit of the satellite link. Tracebox does not show the presence of any PEP: the TCP handshake is correctly performed in the destination network. Only the TCP and UDP checksums are altered by the NATs. Traffic discrimination: We employ Wehe , a state-of-the-art tool to detect Traffic Discrimination (TD). It replays packet traces of 22 popular service including video streaming (e.g., Netflix, YouTube) and video call (e.g., Zoom, Skype). It then replays the same traces with randomized bytes to prevent the operator from correlating this traffic to the original service. In case of Starlink, we launched ten times the complete Wehe tests but could not find any TD policy in place, at least for these popular services. 4

what they can expect in terms of throughput, latency and packet losses when developing solutions that may be used together with Starlink network accesses. A ARTEFACTS

are publicly available. This includes pings, traceroute, Tracebox,

bytes of QUIC packet captures along with their encryption keys. The data can be found online at https://smartdata.polito.it/a-firstlook-at-starlink-performance-open-data/. B ETHICAL CONSIDERATIONS Our work does not employ data coming from individuals as it is

we took care to avoid harming the destination servers, anchors and crawled webpages. We run ping measurements towards anchors every five minutes and perform speed test approximately every hour. We believe such a workload cannot harm the proper operation of the targets. Regarding web measurements, we contacted each website approximately once per hour. Considering that the target of our analysis were some of the most popular websites in Western countries, our belief is not to have caused an overload on the servers or any undesirable side effect. 135 A First Look at Starlink Performance IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France

of the QUIC transport protocol and HTTP/3. https://github.com/cloudflare/quiche/tree/ ba87786836ab4ecfadf9f80a95e3da34ef0e1886 2022-05-13. Browsertime. https://www.sitespeed.io/documentation/browsertime/ 2022-05-13. Disney+ Internet speed recommendations. https: //help.disneyplus.com/csp?id=csp_article_content&sys_kb_id= bb07d3cd1b8d0010b8651f861a4bcbfd 2022-05-13. @ElonMusk, Twitter, on ISL activation. https://twitter.com/elonmusk/ status/1535394359373443073 2022-05-13. @ElonMusk, Twitter, on the launch of ISL-enabled satellites. https: //twitter.com/elonmusk/status/1436541063406264320 2022-05-13. Netflix - Internet connection speed recommendations. https://help. netflix.com/en/node/306 2022-05-13. NVIDIA GeForce Now System Requirements. https://www.nvidia. com/it-it/geforce-now/system-reqs 2022-05-13. RIPE Atlas. https://atlas.ripe.net/ 2022-05-13. Space.com - SpaceX lofts 49 Starlink internet satellites to orbit in 1st launch of 2022. https://www.space.com/spacex-starlink-launch-success-january2022 2022-05-13. Speed Index. https://web.dev/speed-index/ 2022-05-13. Speedtest CLI. https://www.speedtest.net/it/apps/cli 2022-05-13. Starlink. https://www.starlink.com/ 2022-05-13. Website Traffic Analysis & Competitive Intelligence, SimilarWeb. https: //www.similarweb.com/ Waqar Aqeel, Balakrishnan Chandrasekaran, Anja Feldmann, and Bruce M Maggs. 2020. On landing and internal web pages: The strange case of jekyll and hyde in web performance measurement. In Proceedings of the ACM Internet Measurement Conference. 680‚Äì695. "AT&T". . Fixed Wireless Internet. https://www.att.com/internet/fixedwireless/. Mike Bishop. 2021. Hypertext Transfer Protocol Version 3 (HTTP/3). Internet-Draft draft-ietf-quic-http-34. Internet Engineering Task Force. https://datatracker.ietf. org/doc/html/draft-ietf-quic-http-34 Work in Progress. Ranveer Chandra and Thomas Moscibroda. 2019. Perspective: White space networking with Wi-Fi like connectivity. ACM SIGCOMM Computer Communication Review 49, 5 (2019), 107‚Äì109. Paolo Chini, Giovanni Giambene, and Sastri Kota. 2010. A survey on mobile satellite systems. International Journal of Satellite Communications and Networking 28, 1 (2010), 29‚Äì57. Diego Neves da Hora, Alemnew Sheferaw Asrese, Vassilis Christophides, Renata Teixeira, and Dario Rossi. 2018. Narrowing the gap between QoS metrics and Web QoE using Above-the-fold metrics. In International Conference on Passive and Active Network Measurement. Springer, 31‚Äì43. Gregory Detal, Benjamin Hesmans, Olivier Bonaventure, Yves Vanaubel, and Benoit Donnet. 2013. Revealing middlebox interference with tracebox. In Proceedings of the 2013 conference on Internet measurement conference. 1‚Äì8. Nick Feamster and Jason Livingood. 2020. Measuring internet speed: current challenges and future recommendations. Commun. ACM 63, 12 (2020), 72‚Äì80. "Broadband Forum". 2016. "TR-348 Hybrid Access Broadband Network Architecture". Jim Griner, John Border, Markku Kojo, Zach D. Shelby, and Gabriel Montenegro. 2001. Performance Enhancing Proxies Intended to Mitigate Link-Related Degradations. RFC 3135. https://doi.org/10.17487/RFC3135 Sangtae Ha, Injong Rhee, and Lisong Xu. 2008. CUBIC: a new TCP-friendly high-speed TCP variant. ACM SIGOPS operating systems review 42, 5 (2008), 64‚Äì74. ITU-T. 2003. Recommendation G.114: One-way transmission time. Technical Report. Jana Iyengar and Martin Thomson. 2021. QUIC: A UDP-Based Multiplexed and Secure Transport. RFC 9000. https://doi.org/10.17487/RFC9000 Simon Kassing, Debopam Bhattacherjee, Andr√© Baptista √Åguas, Jens Eirik Saethre, and Ankit Singla. 2020. Exploring the" Internet from space" with Hypatia. In Proceedings of the ACM Internet Measurement Conference. 214‚Äì229. Nicolas Keukeleire, Benjamin Hesmans, and Olivier Bonaventure. 2020. Increasing broadband reach with hybrid access networks. IEEE Communications Standards Magazine 4, 1 (2020), 43‚Äì49. Ali Safari Khatouni, Marco Mellia, Marco Ajmone Marsan, Stefan Alfredsson, Jonas Karlsson, Anna Brunstrom, Ozgu Alay, Andra Lutu, Cise Midoglu, and Vincenzo Mancuso. 2017. Speedtest-like measurements in 3g/4g networks: The monroe experience. In 2017 29th International Teletraffic Congress (ITC 29), Vol. 1. IEEE, 169‚Äì177. Oltjon Kodheli, Eva Lagunas, Nicola Maturo, Shree Krishna Sharma, Bhavani Shankar, Jesus Fabian Mendoza Montoya, Juan Carlos Merlano Duncan, Danilo Spano, Symeon Chatzinotas, Steven Kisseleff, et al. 2020. Satellite communications in the new space era: A survey and future challenges. IEEE Communications Surveys & Tutorials 23, 1 (2020), 70‚Äì109. Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles Krasic, Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar, et al. 2017. The quic transport protocol: Design and internet-scale deployment. In Proceedings of the conference of the ACM special interest group on data communication. 183‚Äì 196. DongJin Lee, Brian E Carpenter, and Nevil Brownlee. 2010. Observations of UDP to TCP ratio and port numbers. In 2010 Fifth International Conference on Internet Monitoring and Protection. IEEE, 99‚Äì104. Fangfan Li, Arian Akhavan Niaki, David Choffnes, Phillipa Gill, and Alan Mislove. 2019. A large-scale analysis of deployed traffic differentiation practices. In Proceedings of the ACM Special Interest Group on Data Communication. 130‚Äì144. Mohamed M. Kassem, Aravindh Raman, Diego Perino, and Nishanth Sastry. 2022. A Browser-side View of Starlink Connectivity. In Proceedings of the 2022 Internet Measurement Conference. https://doi.org/10.1145/3517745.3561457 Kyle MacMillan, Tarun Mangla, James Saxon, Nicole P Marwell, and Nick Feamster. . A Comparative Analysis of Ookla Speedtest and Measurement Labs Network Diagnostic Test (NDT7). (). Fran√ßois Michel and Olivier Bonaventure. 2021. Packet delivery time as a tiebreaker for assessing Wi-Fi access points. IAB Workshop on Measuring Network Quality for End-Users (2021). Daniel Perdices, Gianluca Perna, Martino Trevisan, Danilo Giordano, and Marco Mellia. 2022. When Satellite is All You Have When Satellite is All You Have: Watching the Internet from 550 ms. In Proceedings of the 2022 Internet Measurement Conference. https://doi.org/10.1145/3517745.3561432 Mohammad Rajiullah, Andra Lutu, Ali Safari Khatouni, Mah-Rukh Fida, Marco Mellia, Anna Brunstrom, Ozgu Alay, Stefan Alfredsson, and Vincenzo Mancuso. 2019. Web experience in mobile networks: Lessons from two million page visits. In The world wide web conference. 1532‚Äì1543. Eric Rescorla. 2018. The Transport Layer Security (TLS) Protocol Version 1.3. RFC 8446. https://doi.org/10.17487/RFC8446 Jan R√ºth, Ingmar Poese, Christoph Dietzel, and Oliver Hohlfeld. 2018. A First Look at QUIC in the Wild. In International Conference on Passive and Active Network Measurement. Springer, 255‚Äì268. Kevin Thompson, Gregory J Miller, and Rick Wilder. 1997. Wide-area Internet traffic patterns and characteristics. IEEE network 11, 6 (1997), 10‚Äì23. Martino Trevisan, Danilo Giordano, Idilio Drago, Maurizio Matteo Munaf√≤, and Marco Mellia. 2020. Five years at the edge: Watching internet from the isp network. IEEE/ACM Transactions on Networking 28, 2 (2020), 561‚Äì574. M. Trevisan, A. S. Khatouni, and D. Giordano. 2020. ERRANT: Realistic emulation of radio access networks. Computer Networks 176 (2020), 107289. Johannes Zirngibl, Philippe Buschmann, Patrick Sattler, Benedikt Jaeger, Juliane Aulbach, and Georg Carle. 2021. It‚Äôs over 9000: analyzing early QUIC deployments with the standardization on the horizon. In Proceedings of the 21st ACM Internet Measurement Conference. 261‚Äì275. 136

Internet access technologies and Internet protocols are constantly evolving. Broadband technologies such as xDSL and cable modems are prevalent today, but they are being replaced by optical fibers. In densely populated areas, such as cities, fiber deployment can be profitable, while in rural or mountainous areas, however, it can be much more expensive. For this reason, network operators have been working on other Internet access technologies since considerable time. Some propose Fixed Wireless Access (FWA) technologies . Others are deploying hybrid networks that ‚àóFran√ßois Michel is FNRS Research Fellow ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or affiliate of a national government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France ¬© 2022 Association for Computing Machinery. ACM ISBN 978-1-4503-9259-4/22/10...$15.00 https://doi.org/10.1145/3517745.3561416 combine cellular and xDSL . Given the opportunities offered by these rural areas, several companies nowadays offer satellitebased Internet access solutions. Classical Satellite Communications (SatCom) use geostationary satellites with at an orbit of 22 236 miles. A single satellite can cover a large portion of the Earth at the price of a latency of several hundreds of milliseconds due to their high elevation . Such communication technology may provide connectivity to thousands customers with connections easily reaching a speed up to 100 MB, with the drawback of a minimum latency of about 600 ms .

Measure Network Duration Target Latency Starlink 5 Months 11 Anchors Throughput Starlink 4 Months Ookla Servers SatCom 2 Weeks Web Browsing Starlink 4 Months 120 Websites SatCom 2 Weeks QUIC H3 Starlink 5 Months Our server QUIC messages Starlink 5 Months Our server York, Fremont) and Asia (Singapore). We also include 4 nodes of the RIPE Atlas project hosted by volunteers in the same country as our Starlink connection (Belgium). Every five minutes, we measure the latency towards the anchors running 3 pings. We also measure the link latency under light and heavy network load by studying the evolution of the Round-Trip Time (RTT) measured by QUIC with our messages and H3 transfers. Packet loss. Starlink provides a new kind of wireless network access. In general, packet losses come from two causes: congestion or medium imperfection (e.g., Wi-Fi interferences). We study the packet losses under light and heavy network load using our QUIC setup with both bulk H3 transfers and messages variants. Throughput. We measure Starlink download and upload throughput using the command line version of the Ookla SpeedTest service . The application selects the closest test server and probes download and upload capacity by opening several parallel TCP connections. We perform a speed test every half an hour using PC-Wired from 20 December to April 7 2022. We compare Starlink with SatCom using PC-SatCom, on which we run identical measurements, scheduling them at the same pace. Finally, we also measure Starlink throughput using our QUIC H3 setup. Web Browsing. We measure the performance of Starlink for Web browsing by running on PC-Starlink automatic visits to websites and collect metrics that can be used as proxy for users‚Äô perceived QoE. We rely on BrowserTime, a tool performing automated visits to websites . We rely on the rank provided by SimilarWeb , an online ranking service out of which we pick the top-120 website for Belgium. Among the statistics collected with BrowserTime, we focus on two metrics that have been shown to be correlated with users‚Äô QoE : (i) onLoad: the time when the browser fires the onLoad event ‚Äì i.e., when all elements of the page have been downloaded and parsed; (ii) SpeedIndex: proposed by Google , it represents the time at which the visible parts of the page are displayed. It is computed by recording the video of the browser screen and tracking the visual progress of the page during rendering. Every half an hour, we test 30 websites chosen at random and ensure

(LEO) satellites to dramatically reduce communications latency. The first large-scale deployment of this kind is the Starlink constellation, currently operating more than two thousand satellites. The commercial service started in beta version in October 2020 in the United States and from 2021 in European countries. It promises Internet access with latency on the order of 20 ms and bandwidth speeds between 100 and 200 Mbps . Being this a newborn service, its operation and performance have not been fully investigated yet. The only comparable work has been proposed by Kassem et al. , which shows how Starlink performance changes from different vantage points. We here focus on how the performance of a single Starlink vantage point changes when accessing globally distributed resources, under high and heavy network loads, with the TCP and QUIC transport protocols. For many years, TCP has been the dominant protocol for Internet services . SatCom operators therefore widely adopt TCP Performance Enhancing Proxies  (PEP) to mitigate the impact of increased latency on TCP performance. Recently, the Internet Engineering Task Force (IETF) has standardized the QUIC protocol . In short, QUIC combines the features of TCP and TLS  into a single protocol above UDP. QUIC is already widely deployed by major cloud providers and it drives a growing share of Internet traffic . In contrast with TCP, QUIC cannot be optimized by using PEPs in satellite networks since QUIC packets are encrypted and authenticated. Given the current growth of QUIC traffic, it is important to evaluate new access networks using both QUIC and TCP. In this paper, we benchmark the Starlink service and compare it to traditional SatCom networks. We measure the performance in terms of throughput for QUIC and TCP, latency, and packet loss, and find that Starlink delivers on its performance promises and enables the use of demanding services such as high-definition video streaming or cloud gaming. We also find that Quality of Experience (QoE) for Web browsing with Starlink is far better than with traditional SatCom and comes close to wired access. To enable 130 IMC ‚Äô22, October 25‚Äì27, 2022, Nice, France Michel et al.

scale measurement campaign in 2018 involving 4 European MNOs in 2 countries. For download, they found that in the best case (4G with good signal quality), mobile networks provide a median throughput of 29.5 Mbit/s. For upload, the authors found a median bitrate of 14 Mbit/s, comparable to Starlink‚Äôs 17 Mbit/s. However, keep in mind that these throughput measurements  are already 4 years old at the time of writing and thus possibly outdated. HTTP/3 transfers: We now measure throughput using HTTP/3 with our server located in Belgium, the same country as the Starlink access. We report the measured throughput distribution for the 0 5 10 15 20 25 OnLoad 0.0 0.2 0.4 0.6 0.8 1.0 CDF (a) onLoad. 0 5 10 15 20 Speed Index Starlink SatCom Wired (b) SpeedIndex. Figure 6: Web browsing performance. download and upload of 100MB of data in Figure 5. We ran two experiment sessions, one until the 7ùë°‚Ñéof April and one starting from the 25ùë°‚Ñéof April. We observed a difference of download throughput during the two sessions but the upload throughput stayed the same. All the parameters are the same for the two sessions but we observed an increase of download capacity for QUIC. Figure 5

This study presents an initial characterization of Starlink from the perspective of a single site in Western Europe. Our TCP and QUIC measurements show that Starlink delivers on its promised low latency and high throughput. It enables the use of latency-sensitive services that struggle with traditional SatCom. Interestingly, early simulations of LEO constellations (see Hypatia , among others) predicted similarly low values for RTT, especially in this first phase of low utilization. However, we emphasize the presence of (moderate) packet loss even at low network utilization. Given the limited time between the commercial launch of Starlink and this study, our ping latency measurements are still in the early stages in terms of temporal and spatial scale. As we aim at tracking latency evolution over time, the number of anchors we probe is limited and does not allow us to provide a complete picture of latency for a comprehensive set of targets worldwide. Inter-satellite links do not seem to be enabled, but Starlink plans to deploy them by the end of 2022. At that time, coverage will be significantly expanded, and it will be possible to study how packets are routed through the sky and how performance varies around the globe. Our QUIC measurements reveal additional details about the RTTs and packet losses under load. During HTTP/3 bulk transfers, RTTs increase more than when applications exchange messages at a low rate. Thanks to QUIC‚Äôs precise acknowledgments, our measurements show that packet losses are more frequent during bulk transfers and provide some characterization of the loss patterns. At the application level, we have studied QoE for web browsing and found it to be radically better than traditional SatCom. Note, however, that we only studied a limited number of websites because we wanted to visit them hourly. We did not account for differences in experience that could be due to different browsers, different devices, or other factors. Also, we only visited landing pages, while a more realistic campaign should include internal pages . Finally, further measurements should assess QoE for a wider range of services, since in many cases (e.g. video calls) there are wellestablished performance indicators to study. However, we believe

2022. Savoury